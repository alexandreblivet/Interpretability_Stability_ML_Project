{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0b7463d",
   "metadata": {},
   "source": [
    "# This the notebook which will adress step 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73ad23a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(83189) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90bd9f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (1086236, 39)\n",
      "Columns: ['Unnamed: 0', 'issue_d', 'loan duration', 'annual_inc', 'avg_cur_bal', 'bc_open_to_buy', 'bc_util', 'delinq_2yrs', 'dti', 'emp_length', 'emp_title', 'fico_range_high', 'funded_amnt', 'grade', 'home_ownership', 'inq_last_6mths', 'int_rate', 'mo_sin_old_rev_tl_op', 'mo_sin_rcnt_rev_tl_op', 'mo_sin_rcnt_tl', 'mort_acc', 'mths_since_recent_bc', 'num_actv_bc_tl', 'num_bc_tl', 'num_il_tl', 'num_rev_accts', 'open_acc', 'pub_rec', 'pub_rec_bankruptcies', 'purpose', 'revol_bal', 'revol_util', 'sub_grade', 'target', 'tax_liens', 'zip_code', 'Pct_afro_american', 'Predictions', 'Predicted probabilities']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>issue_d</th>\n",
       "      <th>loan duration</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>avg_cur_bal</th>\n",
       "      <th>bc_open_to_buy</th>\n",
       "      <th>bc_util</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>dti</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>...</th>\n",
       "      <th>purpose</th>\n",
       "      <th>revol_bal</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>target</th>\n",
       "      <th>tax_liens</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>Pct_afro_american</th>\n",
       "      <th>Predictions</th>\n",
       "      <th>Predicted probabilities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>0</td>\n",
       "      <td>39600.0</td>\n",
       "      <td>1379.0</td>\n",
       "      <td>21564.0</td>\n",
       "      <td>16.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.49</td>\n",
       "      <td>2 years</td>\n",
       "      <td>...</td>\n",
       "      <td>home_improvement</td>\n",
       "      <td>4136.0</td>\n",
       "      <td>16.1</td>\n",
       "      <td>B2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>782</td>\n",
       "      <td>7.388592</td>\n",
       "      <td>0</td>\n",
       "      <td>0.053051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>0</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>9570.0</td>\n",
       "      <td>16473.0</td>\n",
       "      <td>53.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.87</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>...</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>36638.0</td>\n",
       "      <td>61.2</td>\n",
       "      <td>B2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>481</td>\n",
       "      <td>9.745456</td>\n",
       "      <td>0</td>\n",
       "      <td>0.084507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2013</td>\n",
       "      <td>0</td>\n",
       "      <td>325000.0</td>\n",
       "      <td>53306.0</td>\n",
       "      <td>13901.0</td>\n",
       "      <td>67.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.55</td>\n",
       "      <td>5 years</td>\n",
       "      <td>...</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>29581.0</td>\n",
       "      <td>54.6</td>\n",
       "      <td>A3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>945</td>\n",
       "      <td>7.542862</td>\n",
       "      <td>0</td>\n",
       "      <td>0.037206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2013</td>\n",
       "      <td>0</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>36362.0</td>\n",
       "      <td>3567.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.03</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>...</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>10805.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>B3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>809</td>\n",
       "      <td>6.598132</td>\n",
       "      <td>0</td>\n",
       "      <td>0.061371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>73000.0</td>\n",
       "      <td>24161.0</td>\n",
       "      <td>4853.0</td>\n",
       "      <td>74.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.13</td>\n",
       "      <td>6 years</td>\n",
       "      <td>...</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>27003.0</td>\n",
       "      <td>82.8</td>\n",
       "      <td>D5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>802</td>\n",
       "      <td>7.058900</td>\n",
       "      <td>1</td>\n",
       "      <td>0.345896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  issue_d  loan duration  annual_inc  avg_cur_bal  \\\n",
       "0           0     2013              0     39600.0       1379.0   \n",
       "1           1     2013              0     55000.0       9570.0   \n",
       "2           2     2013              0    325000.0      53306.0   \n",
       "3           3     2013              0    130000.0      36362.0   \n",
       "4           4     2013              1     73000.0      24161.0   \n",
       "\n",
       "   bc_open_to_buy  bc_util  delinq_2yrs    dti emp_length  ...  \\\n",
       "0         21564.0     16.1          0.0   2.49    2 years  ...   \n",
       "1         16473.0     53.9          0.0  22.87  10+ years  ...   \n",
       "2         13901.0     67.1          0.0  18.55    5 years  ...   \n",
       "3          3567.0     93.0          0.0  13.03  10+ years  ...   \n",
       "4          4853.0     74.7          1.0  23.13    6 years  ...   \n",
       "\n",
       "              purpose  revol_bal  revol_util sub_grade target  tax_liens  \\\n",
       "0    home_improvement     4136.0        16.1        B2      0        0.0   \n",
       "1  debt_consolidation    36638.0        61.2        B2      0        0.0   \n",
       "2  debt_consolidation    29581.0        54.6        A3      0        0.0   \n",
       "3  debt_consolidation    10805.0        67.0        B3      0        0.0   \n",
       "4  debt_consolidation    27003.0        82.8        D5      1        0.0   \n",
       "\n",
       "   zip_code  Pct_afro_american  Predictions  Predicted probabilities  \n",
       "0       782           7.388592            0                 0.053051  \n",
       "1       481           9.745456            0                 0.084507  \n",
       "2       945           7.542862            0                 0.037206  \n",
       "3       809           6.598132            0                 0.061371  \n",
       "4       802           7.058900            1                 0.345896  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data_path = 'data/dataproject2025.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99cbb382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully: <class 'dict'>\n",
      "Model parameters: {'objective': 'binary:logistic', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': 0.85, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': 'logloss', 'feature_types': None, 'feature_weights': None, 'gamma': 0.1, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': 0.08, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': 7, 'max_leaves': None, 'min_child_weight': 3, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': 800, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': 42, 'reg_alpha': 0.1, 'reg_lambda': 0.5, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': 0.85, 'tree_method': 'hist', 'validate_parameters': None, 'verbosity': 0}\n",
      "Direct model (no preprocessing pipeline)\n"
     ]
    }
   ],
   "source": [
    "# Load the trained XGBoost model\n",
    "model_path = 'models/xgboost_black_box_model.joblib'\n",
    "model = joblib.load(model_path)\n",
    "\n",
    "print(f\"Model loaded successfully: {type(model)}\")\n",
    "# Access the actual model object from the dictionary\n",
    "xgb_model = model['xgb_model']\n",
    "print(f\"Model parameters: {xgb_model.get_params()}\")\n",
    "\n",
    "# Check if it's a Pipeline (which includes the preprocessor)\n",
    "if hasattr(model, 'named_steps'):\n",
    "    print(\"Pipeline steps:\")\n",
    "    for step_name in model.named_steps.keys():\n",
    "        print(f\"  - {step_name}: {type(model.named_steps[step_name])}\")\n",
    "else:\n",
    "    print(\"Direct model (no preprocessing pipeline)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52e70ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns:\n",
      "1. Unnamed: 0\n",
      "2. issue_d\n",
      "3. loan duration\n",
      "4. annual_inc\n",
      "5. avg_cur_bal\n",
      "6. bc_open_to_buy\n",
      "7. bc_util\n",
      "8. delinq_2yrs\n",
      "9. dti\n",
      "10. emp_length\n",
      "11. emp_title\n",
      "12. fico_range_high\n",
      "13. funded_amnt\n",
      "14. grade\n",
      "15. home_ownership\n",
      "16. inq_last_6mths\n",
      "17. int_rate\n",
      "18. mo_sin_old_rev_tl_op\n",
      "19. mo_sin_rcnt_rev_tl_op\n",
      "20. mo_sin_rcnt_tl\n",
      "21. mort_acc\n",
      "22. mths_since_recent_bc\n",
      "23. num_actv_bc_tl\n",
      "24. num_bc_tl\n",
      "25. num_il_tl\n",
      "26. num_rev_accts\n",
      "27. open_acc\n",
      "28. pub_rec\n",
      "29. pub_rec_bankruptcies\n",
      "30. purpose\n",
      "31. revol_bal\n",
      "32. revol_util\n",
      "33. sub_grade\n",
      "34. target\n",
      "35. tax_liens\n",
      "36. zip_code\n",
      "37. Pct_afro_american\n",
      "38. Predictions\n",
      "39. Predicted probabilities\n",
      "\n",
      "Using 'target' as target variable\n",
      "Features shape: (1086236, 36)\n",
      "Target shape: (1086236,)\n",
      "Target distribution:\n",
      "target\n",
      "0    857588\n",
      "1    228648\n",
      "Name: count, dtype: int64\n",
      "Features shape: (1086236, 36)\n",
      "Target shape: (1086236,)\n",
      "Target distribution:\n",
      "target\n",
      "0    857588\n",
      "1    228648\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Prepare the data for modeling\n",
    "# Use 'target' as the target variable - this should be the correct target column\n",
    "target_column = 'target'\n",
    "\n",
    "# Check available columns to identify the target\n",
    "print(\"Available columns:\")\n",
    "for i, col in enumerate(df.columns):\n",
    "    print(f\"{i+1}. {col}\")\n",
    "\n",
    "# Verify the target column exists\n",
    "if target_column in df.columns:\n",
    "    print(f\"\\nUsing '{target_column}' as target variable\")\n",
    "else:\n",
    "    print(f\"\\nTarget column '{target_column}' not found!\")\n",
    "    print(\"Please specify the correct target column name.\")\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(columns=[target_column, 'Predictions', 'Predicted probabilities'])  # Remove predictions too\n",
    "y = df[target_column]\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"Target distribution:\\n{y.value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "844f5156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 868988 samples\n",
      "Test set: 217248 samples\n",
      "Model expects 128 features\n",
      "Categorical columns: ['emp_length', 'emp_title', 'grade', 'home_ownership', 'purpose', 'sub_grade']\n",
      "Preprocessed test data shape: (217248, 128)\n",
      "Features match: True\n",
      "Preprocessed test data shape: (217248, 128)\n",
      "Features match: True\n",
      "\n",
      "Model Performance on Test Set:\n",
      "F1-Score: 0.6971\n",
      "Accuracy: 0.7896\n",
      "\n",
      "Prediction distribution:\n",
      "0    217182\n",
      "1        66\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Model Performance on Test Set:\n",
      "F1-Score: 0.6971\n",
      "Accuracy: 0.7896\n",
      "\n",
      "Prediction distribution:\n",
      "0    217182\n",
      "1        66\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Split the data into train/test sets (same as used during training)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Remove classes with fewer than two samples\n",
    "class_counts = y.value_counts()\n",
    "valid_classes = class_counts[class_counts > 1].index\n",
    "X_filtered = X[y.isin(valid_classes)]\n",
    "y_filtered = y[y.isin(valid_classes)]\n",
    "\n",
    "# Use the same random state as used during model training for consistency\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_filtered, y_filtered, test_size=0.2, random_state=42, stratify=y_filtered\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "\n",
    "# Get the trained features from the model\n",
    "trained_features = model['feature_names_clean']  # Features the model was trained on\n",
    "print(f\"Model expects {len(trained_features)} features\")\n",
    "\n",
    "# Preprocess categorical columns to match training preprocessing\n",
    "categorical_columns = X_test.select_dtypes(include=['object']).columns\n",
    "print(f\"Categorical columns: {categorical_columns.tolist()}\")\n",
    "\n",
    "# Use one-hot encoding for categorical columns\n",
    "X_test_encoded = pd.get_dummies(X_test, columns=categorical_columns)\n",
    "\n",
    "# Add missing columns with default values (0 for one-hot encoded columns)\n",
    "for col in trained_features:\n",
    "    if col not in X_test_encoded.columns:\n",
    "        X_test_encoded[col] = 0\n",
    "\n",
    "# Reorder columns to match the trained features exactly\n",
    "X_test_encoded = X_test_encoded[trained_features]\n",
    "\n",
    "print(f\"Preprocessed test data shape: {X_test_encoded.shape}\")\n",
    "print(f\"Features match: {list(X_test_encoded.columns) == trained_features}\")\n",
    "\n",
    "# Make predictions to verify model performance\n",
    "y_pred = xgb_model.predict(X_test_encoded.values)  # Pass numpy array\n",
    "y_pred_proba = xgb_model.predict_proba(X_test_encoded.values)  # Pass numpy array\n",
    "\n",
    "# Calculate performance metrics\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\nModel Performance on Test Set:\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Show class distribution in predictions\n",
    "print(f\"\\nPrediction distribution:\\n{pd.Series(y_pred).value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0f73a0",
   "metadata": {},
   "source": [
    "## Permutation Importance Analysis\n",
    "\n",
    "Permutation Importance is a model-agnostic method that measures the importance of a feature by calculating the increase in the model's prediction error after permuting the feature's values. The idea is simple: if a feature is important, shuffling its values will significantly degrade model performance.\n",
    "\n",
    "**How it works:**\n",
    "1. Calculate baseline model performance\n",
    "2. For each feature:\n",
    "   - Shuffle the feature's values randomly\n",
    "   - Calculate model performance with shuffled feature\n",
    "   - Measure the decrease in performance\n",
    "3. The importance of a feature is the performance decrease caused by shuffling it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f72d9d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPUTATIONAL COMPLEXITY ANALYSIS:\n",
      "==================================================\n",
      "‚Ä¢ Dataset size: 217,248 samples √ó 128 features\n",
      "‚Ä¢ Estimated model predictions needed: 1,280\n",
      "‚Ä¢ Using 5 repeats instead of 10 (50% faster)\n",
      "‚Ä¢ Large dataset detected - will sample 1000 rows\n",
      "‚Ä¢ This reduces computation by 99.5%\n",
      "\n",
      "Estimated runtime: 2-5 minutes (vs 20+ minutes with original settings)\n",
      "\n",
      "Optimizations applied:\n",
      "  ‚úì Reduced repeats from 10 to 5\n",
      "  ‚úì Single-core processing (avoids multiprocessing overhead)\n",
      "  ‚úì Sample 1000 rows for faster computation\n",
      "  ‚úì Direct numpy arrays to XGBoost model\n"
     ]
    }
   ],
   "source": [
    "# Quick diagnostic - Check computational complexity\n",
    "print(\"COMPUTATIONAL COMPLEXITY ANALYSIS:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "n_samples = X_test_encoded.shape[0]\n",
    "n_features = X_test_encoded.shape[1]\n",
    "n_repeats = 5  # What we'll use in optimized version\n",
    "\n",
    "estimated_predictions = n_features * n_repeats * 2  # 2 predictions per feature per repeat\n",
    "print(f\"‚Ä¢ Dataset size: {n_samples:,} samples √ó {n_features:,} features\")\n",
    "print(f\"‚Ä¢ Estimated model predictions needed: {estimated_predictions:,}\")\n",
    "print(f\"‚Ä¢ Using {n_repeats} repeats instead of 10 (50% faster)\")\n",
    "\n",
    "if n_samples > 1000:\n",
    "    print(f\"‚Ä¢ Large dataset detected - will sample 1000 rows\")\n",
    "    print(f\"‚Ä¢ This reduces computation by {((n_samples-1000)/n_samples)*100:.1f}%\")\n",
    "\n",
    "print(f\"\\nEstimated runtime: 2-5 minutes (vs 20+ minutes with original settings)\")\n",
    "print(\"\\nOptimizations applied:\")\n",
    "print(\"  ‚úì Reduced repeats from 10 to 5\")\n",
    "print(\"  ‚úì Single-core processing (avoids multiprocessing overhead)\")\n",
    "if n_samples > 1000:\n",
    "    print(\"  ‚úì Sample 1000 rows for faster computation\")\n",
    "print(\"  ‚úì Direct numpy arrays to XGBoost model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14bc821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Permutation Importance - FULL DATASET VERSION\n",
    "# This will take longer but use all 217,248 samples for maximum accuracy\n",
    "\n",
    "\n",
    "# Define F1-score scorer for multi-class classification\n",
    "from sklearn.metrics import make_scorer\n",
    "f1_scorer = make_scorer(f1_score, average='weighted')\n",
    "\n",
    "print(f\"\\nüöÄ STARTING COMPUTATION on {X_test_encoded.shape[0]:,} samples...\")\n",
    "print(\"   Progress: This may take 15-30 minutes depending on your hardware\")\n",
    "\n",
    "# Use full dataset - no sampling\n",
    "perm_importance_full = permutation_importance(\n",
    "    xgb_model,  \n",
    "    X_test_encoded.values,  # Full test set\n",
    "    y_test,                 # Full test labels\n",
    "    n_repeats=5,            # Keep 5 repeats for reasonable time\n",
    "    random_state=42,\n",
    "    scoring=f1_scorer,\n",
    "    n_jobs=1               # Single core to avoid memory issues\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Full Dataset Permutation Importance calculation completed!\")\n",
    "\n",
    "# Create results DataFrame for full dataset\n",
    "feature_names_full = X_test_encoded.columns.tolist()\n",
    "importance_df_full = pd.DataFrame({\n",
    "    'feature': feature_names_full,\n",
    "    'importance_mean': perm_importance_full.importances_mean,\n",
    "    'importance_std': perm_importance_full.importances_std\n",
    "}).sort_values('importance_mean', ascending=False)\n",
    "\n",
    "print(f\"\\nüìä FULL DATASET RESULTS - Top 10 Most Important Features:\")\n",
    "print(importance_df_full.head(10).to_string(index=False))\n",
    "\n",
    "# Compare with sampled results\n",
    "print(f\"\\nüîç COMPARISON: Sample vs Full Dataset\")\n",
    "print(\"=\"*60)\n",
    "sample_top5 = importance_df.head(5)['feature'].tolist()\n",
    "full_top5 = importance_df_full.head(5)['feature'].tolist()\n",
    "\n",
    "print(\"Top 5 features (Sampled):\", sample_top5)\n",
    "print(\"Top 5 features (Full):   \", full_top5)\n",
    "print(f\"Overlap in top 5: {len(set(sample_top5) & set(full_top5))}/5 features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7883c8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Permutation Importance Results\n",
    "\n",
    "# 1. Bar plot of top 15 most important features\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_features = importance_df.head(15)\n",
    "\n",
    "plt.barh(range(len(top_features)), top_features['importance_mean'], \n",
    "         xerr=top_features['importance_std'], capsize=5, alpha=0.7)\n",
    "plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "plt.xlabel('Permutation Importance (F1-Score Decrease)')\n",
    "plt.title('Top 15 Features by Permutation Importance\\n(Higher values indicate more important features)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Invert y-axis to show most important at top\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. Histogram of importance scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(importance_df['importance_mean'], bins=30, alpha=0.7, edgecolor='black')\n",
    "plt.xlabel('Permutation Importance Score')\n",
    "plt.ylabel('Number of Features')\n",
    "plt.title('Distribution of Permutation Importance Scores')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a04edee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed Analysis of Feature Importance\n",
    "\n",
    "print(\"=== PERMUTATION IMPORTANCE ANALYSIS RESULTS ===\\n\")\n",
    "\n",
    "# Statistical summary\n",
    "print(f\"Total number of features analyzed: {len(importance_df)}\")\n",
    "print(f\"Mean importance score: {importance_df['importance_mean'].mean():.6f}\")\n",
    "print(f\"Standard deviation: {importance_df['importance_mean'].std():.6f}\")\n",
    "print(f\"Maximum importance: {importance_df['importance_mean'].max():.6f}\")\n",
    "print(f\"Minimum importance: {importance_df['importance_mean'].min():.6f}\")\n",
    "\n",
    "# Features with significant positive importance (above mean + 1 std)\n",
    "threshold = importance_df['importance_mean'].mean() + importance_df['importance_mean'].std()\n",
    "significant_features = importance_df[importance_df['importance_mean'] > threshold]\n",
    "print(f\"\\nFeatures with high importance (> {threshold:.6f}):\")\n",
    "print(f\"Count: {len(significant_features)}\")\n",
    "if len(significant_features) > 0:\n",
    "    for idx, row in significant_features.iterrows():\n",
    "        print(f\"  - {row['feature']}: {row['importance_mean']:.6f} ¬± {row['importance_std']:.6f}\")\n",
    "\n",
    "# Features with near-zero importance\n",
    "near_zero = importance_df[importance_df['importance_mean'] <= 0.001]\n",
    "print(f\"\\nFeatures with near-zero importance (<= 0.001):\")\n",
    "print(f\"Count: {len(near_zero)}\")\n",
    "if len(near_zero) > 0:\n",
    "    print(\"These features have minimal impact on model performance:\")\n",
    "    for idx, row in near_zero.head(10).iterrows():\n",
    "        print(f\"  - {row['feature']}: {row['importance_mean']:.6f}\")\n",
    "    if len(near_zero) > 10:\n",
    "        print(f\"  ... and {len(near_zero) - 10} more\")\n",
    "\n",
    "# Top 5 most important features detailed analysis\n",
    "print(f\"\\n=== TOP 5 MOST IMPORTANT FEATURES ===\")\n",
    "top_5 = importance_df.head(5)\n",
    "for idx, row in top_5.iterrows():\n",
    "    print(f\"\\n{idx + 1}. {row['feature']}\")\n",
    "    print(f\"   Importance: {row['importance_mean']:.6f} ¬± {row['importance_std']:.6f}\")\n",
    "    print(f\"   Interpretation: Shuffling this feature decreases F1-score by {row['importance_mean']:.4f} on average\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75446f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with XGBoost Built-in Feature Importance\n",
    "\n",
    "# Get XGBoost's built-in feature importance from the actual model\n",
    "if hasattr(xgb_model, 'feature_importances_'):\n",
    "    # Get built-in feature importance\n",
    "    builtin_importance = xgb_model.feature_importances_\n",
    "    \n",
    "    # Use the same feature names as used for permutation importance\n",
    "    transformed_feature_names = feature_names\n",
    "    \n",
    "    # Create comparison DataFrame if dimensions match\n",
    "    if len(builtin_importance) == len(importance_df):\n",
    "        comparison_df = pd.DataFrame({\n",
    "            'feature': feature_names,\n",
    "            'permutation_importance': importance_df['importance_mean'],\n",
    "            'xgboost_importance': builtin_importance\n",
    "        })\n",
    "    else:\n",
    "        print(f\"Note: Different number of features between permutation ({len(importance_df)}) and built-in importance ({len(builtin_importance)})\")\n",
    "        print(\"This suggests a mismatch in feature processing.\")\n",
    "        \n",
    "        # Create separate analysis for built-in importance\n",
    "        builtin_df = pd.DataFrame({\n",
    "            'feature': [f'feature_{i}' for i in range(len(builtin_importance))],\n",
    "            'xgboost_importance': builtin_importance\n",
    "        }).sort_values('xgboost_importance', ascending=False)\n",
    "        \n",
    "        print(f\"\\nTop 10 Features by XGBoost Built-in Importance:\")\n",
    "        print(builtin_df.head(10).to_string(index=False))\n",
    "        \n",
    "        # Visualize XGBoost importance\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        top_xgb = builtin_df.head(15)\n",
    "        plt.barh(range(len(top_xgb)), top_xgb['xgboost_importance'], alpha=0.7)\n",
    "        plt.yticks(range(len(top_xgb)), top_xgb['feature'])\n",
    "        plt.xlabel('XGBoost Feature Importance')\n",
    "        plt.title('Top 15 Features by XGBoost Built-in Importance')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        comparison_df = None\n",
    "else:\n",
    "    print(\"Built-in feature importance not available for this model type\")\n",
    "    comparison_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bba197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison visualization if both importance measures are available\n",
    "if comparison_df is not None:\n",
    "    # Normalize both importance measures for better comparison\n",
    "    comparison_df['perm_importance_norm'] = (comparison_df['permutation_importance'] - comparison_df['permutation_importance'].min()) / (comparison_df['permutation_importance'].max() - comparison_df['permutation_importance'].min())\n",
    "    comparison_df['xgb_importance_norm'] = (comparison_df['xgboost_importance'] - comparison_df['xgboost_importance'].min()) / (comparison_df['xgboost_importance'].max() - comparison_df['xgboost_importance'].min())\n",
    "    \n",
    "    # Create scatter plot comparing both methods\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.scatter(comparison_df['xgb_importance_norm'], comparison_df['perm_importance_norm'], alpha=0.6)\n",
    "    \n",
    "    # Add diagonal line for perfect correlation\n",
    "    max_val = max(comparison_df['xgb_importance_norm'].max(), comparison_df['perm_importance_norm'].max())\n",
    "    plt.plot([0, max_val], [0, max_val], 'r--', alpha=0.5, label='Perfect Correlation')\n",
    "    \n",
    "    plt.xlabel('XGBoost Built-in Importance (Normalized)')\n",
    "    plt.ylabel('Permutation Importance (Normalized)')\n",
    "    plt.title('Comparison of Feature Importance Methods')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate correlation between the two methods\n",
    "    correlation = comparison_df['permutation_importance'].corr(comparison_df['xgboost_importance'])\n",
    "    print(f\"Correlation between Permutation and XGBoost importance: {correlation:.4f}\")\n",
    "    \n",
    "    # Show features that rank differently in both methods\n",
    "    comparison_df['perm_rank'] = comparison_df['permutation_importance'].rank(ascending=False)\n",
    "    comparison_df['xgb_rank'] = comparison_df['xgboost_importance'].rank(ascending=False)\n",
    "    comparison_df['rank_diff'] = abs(comparison_df['perm_rank'] - comparison_df['xgb_rank'])\n",
    "    \n",
    "    print(\"\\nFeatures with largest ranking differences between methods:\")\n",
    "    rank_diff_df = comparison_df.nlargest(10, 'rank_diff')[['feature', 'perm_rank', 'xgb_rank', 'rank_diff']]\n",
    "    print(rank_diff_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f44396e",
   "metadata": {},
   "source": [
    "## Key Insights and Business Interpretation\n",
    "\n",
    "Based on the Permutation Importance analysis, we can identify the main drivers of predictive performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8a8d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary Report - Main Drivers of Predictive Performance\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"PERMUTATION IMPORTANCE ANALYSIS - EXECUTIVE SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get top performing features\n",
    "top_drivers = importance_df.head(10)\n",
    "\n",
    "print(f\"\\nüìä ANALYSIS OVERVIEW:\")\n",
    "print(f\"‚Ä¢ Total features analyzed: {len(importance_df)}\")\n",
    "print(f\"‚Ä¢ Model performance (F1-Score): {f1:.4f}\")\n",
    "print(f\"‚Ä¢ Analysis method: Permutation Importance with 10 repetitions\")\n",
    "\n",
    "print(f\"\\nüéØ TOP 10 PERFORMANCE DRIVERS:\")\n",
    "print(f\"{'Rank':<4} {'Feature':<25} {'Importance':<12} {'Impact'}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for idx, (_, row) in enumerate(top_drivers.iterrows(), 1):\n",
    "    impact = \"High\" if row['importance_mean'] > threshold else \"Moderate\"\n",
    "    print(f\"{idx:<4} {row['feature']:<25} {row['importance_mean']:<12.6f} {impact}\")\n",
    "\n",
    "print(f\"\\nüí° KEY INSIGHTS:\")\n",
    "critical_features = importance_df[importance_df['importance_mean'] > threshold]\n",
    "print(f\"‚Ä¢ {len(critical_features)} features are critical for model performance\")\n",
    "print(f\"‚Ä¢ Top feature contributes {top_drivers.iloc[0]['importance_mean']:.4f} to F1-score\")\n",
    "print(f\"‚Ä¢ {len(near_zero)} features have minimal impact on predictions\")\n",
    "\n",
    "if len(critical_features) > 0:\n",
    "    print(f\"\\n‚ö†Ô∏è  CRITICAL SUCCESS FACTORS:\")\n",
    "    print(\"These features are essential for maintaining model performance:\")\n",
    "    for idx, row in critical_features.iterrows():\n",
    "        print(f\"  ‚Ä¢ {row['feature']}: {row['importance_mean']:.6f} importance score\")\n",
    "\n",
    "print(f\"\\nüîç RECOMMENDATIONS:\")\n",
    "print(\"1. Monitor the top 5 features closely in production\")\n",
    "print(\"2. Ensure data quality for critical features\")\n",
    "print(\"3. Consider feature engineering based on top drivers\")\n",
    "print(\"4. Investigate features with near-zero importance for potential removal\")\n",
    "\n",
    "# Save results to file for later use\n",
    "importance_df.to_csv('models/permutation_importance_results.csv', index=False)\n",
    "print(f\"\\nüíæ Results saved to: models/permutation_importance_results.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
